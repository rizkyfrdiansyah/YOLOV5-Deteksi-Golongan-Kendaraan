# -*- coding: utf-8 -*-
"""Deteksi Golongan Kendaraan Jalan Tol  Lingkar Luar Jakarta Timur YOLOv5-Custom-Training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15VQDlbgqJF2_SauRG_2lyOf9h9nPPmCo

# Custom Training with YOLOv5

In this tutorial, we assemble a dataset and train a custom YOLOv5 model to recognize the objects in our dataset. To do so we will take the following steps:

* Gather a dataset of images and label our dataset
* Export our dataset to YOLOv5
* Train YOLOv5 to recognize the objects in our dataset
* Evaluate our YOLOv5 model's performance
* Run test inference to view our model at work



![](https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png)

# Step 1: Install Requirements
"""

# Commented out IPython magic to ensure Python compatibility.
#clone YOLOv5 and
!git clone https://github.com/ultralytics/yolov5  # clone repo
# %cd yolov5
# %pip install -qr requirements.txt # install dependencies
# %pip install -q roboflow

import torch
import os
from IPython.display import Image, clear_output  # to display images

print(f"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})")

"""# Step 2: Assemble Our Dataset

In order to train our custom model, we need to assemble a dataset of representative images with bounding box annotations around the objects that we want to detect. And we need our dataset to be in YOLOv5 format.

In Roboflow, you can choose between two paths:

* Convert an existing dataset to YOLOv5 format. Roboflow supports over [30 formats object detection formats](https://roboflow.com/formats) for conversion.
* Upload raw images and annotate them in Roboflow with [Roboflow Annotate](https://docs.roboflow.com/annotate).

# Annotate

![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/roboflow-annotate.gif)

# Version

![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/robolfow-preprocessing.png)

"""

from roboflow import Roboflow
rf = Roboflow(model_format="yolov5", notebook="ultralytics")

# set up environment
os.environ["DATASET_DIRECTORY"] = "/content/datasets"

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="fwJRC63UkRjTYxZ3QYTA")
project = rf.workspace("muhammad-rizky-ferdiansyah-00fow").project("jalan-tol-lingkar-luar-jakarta-timur")
dataset = project.version(1).download("yolov5")

"""# Step 3: Train Our Custom YOLOv5 model

Here, we are able to pass a number of arguments:
- **img:** define input image size
- **batch:** determine batch size
- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)
- **data:** Our dataset locaiton is saved in the `dataset.location`
- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.
- **cache:** cache images for faster training

# EXPERIMEN NORMAL MENGGUNAKAN MODEL yolov5s

''' no preprocessing dan no augmentation pada Roboflow '''

# batch 16 dengan epoch 10, 50, 100, 150

# batch 16 epoch 10
"""

!python train.py --img 416 --batch 16 --epochs 10 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""# batch 16 epoch 50"""

!python train.py --img 416 --batch 16 --epochs 50 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""# batch 16 epoch 100"""

!python train.py --img 416 --batch 16 --epochs 100 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""# batch 16 epoch 150"""

!python train.py --img 416 --batch 16 --epochs 150 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""# EXPERIMEN KEDUA
Mengatur imgsize 416, confidence threshold 75 dan iou threshold 0.85
"""

!python train.py --img 416 --batch 16 --epochs 10 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

!python train.py --img 416 --batch 16 --epochs 50 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

!python train.py --img 416 --batch 16 --epochs 100 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""# EXPERIMEN KETIGA
MENGATUR HYPERPARAMETER (hyp.Objects365.yaml)

# batch 32 epoch 5, 50, 100

batch 32 epoch 5
"""

!python train.py --img 416 --batch 32 --epochs 5 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""batch 32 epoch 50"""

!python train.py --img 416 --batch 32 --epochs 50 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""batch 32 epoch 100"""

!python train.py --img 416 --batch 32 --epochs 100 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""# EXPERIMEN KEEMPAT
MENGATUR HYPERPARAMETER (hyp.VOC.yaml)

# batch 32 epoch 10, 75, 150

batch 64 epoch 10
"""

!python train.py --img 416 --batch 64 --epochs 10 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""batch 64 epoch 75"""

!python train.py --img 416 --batch 64 --epochs 75 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""batch 64 epoch 150"""

!python train.py --img 416 --batch 64 --epochs 150 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""# EXPERIMEN KELIMA
MENGATUR HYPERPARAMETER ( hyp.no-augmentation.yaml)

# batch 32 epoch 20, 80, 120
"""

!python train.py --img 416 --batch 32 --epochs 20 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

!python train.py --img 416 --batch 32 --epochs 80 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

!python train.py --img 416 --batch 32 --epochs 120 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""# EXPERIMEN KEENAM
MENGATUR HYPERPARAMETER (hyp.scratch-high.yamL)

# batch 32 epoch 20, 80, 120
"""

!python train.py --img 416 --batch 32 --epochs 20 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

!python train.py --img 416 --batch 32 --epochs 80 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

!python train.py --img 416 --batch 32 --epochs 120 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""# EXPERIMEN KETUJUH
MENGATUR HYPERPARAMETER (hyp.scratch-low.yaml)

# batch 32 epoch 20, 80, 120
"""

!python train.py --img 416 --batch 64 --epochs 20 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

!python train.py --img 416 --batch 64 --epochs 80 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

!python train.py --img 416 --batch 64 --epochs 120 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""# EXPERIMEN KEDELAPAN
MENGATUR HYPERPARAMETER (hyp.scratch-med.yaml)

# batch 32 epoch 20, 80, 120
"""

!python train.py --img 416 --batch 32 --epochs 20 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

!python train.py --img 416 --batch 32 --epochs 80 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

!python train.py --img 416 --batch 32 --epochs 120 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache

"""# Evaluate Custom YOLOv5 Detector Performance
Training losses and performance metrics are saved to Tensorboard and also to a logfile.

If you are new to these metrics, the one you want to focus on is `mAP_0.5` - learn more about mean average precision [here](https://blog.roboflow.com/mean-average-precision/).

# EXPERIMEN 1
"""

# Commented out IPython magic to ensure Python compatibility.
# Start tensorboard
# Launch after you have started training
# logs save in the folder "runs"
# %load_ext tensorboard
# %tensorboard --logdir runs

"""# EXPERIMEN 2"""

# Commented out IPython magic to ensure Python compatibility.
# Start tensorboard
# Launch after you have started training
# logs save in the folder "runs"
# %load_ext tensorboard
# %tensorboard --logdir runs

"""#Run Inference  With Trained Weights
Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow.

# DETECT EXPERIMEN 1
"""

!python detect.py --weights runs/train/exp3/weights/best.pt --img 416 --conf 0.1 --source {dataset.location}/test/images

#display inference on ALL test images

import glob
from IPython.display import Image, display

for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG
    display(Image(filename=imageName))
    print("\n")

"""# DETECT EXPERIMEN 2"""

!python detect.py --weights runs/train/exp6/weights/best.pt --img 416 --conf 0.75 --source {dataset.location}/test/images

#display inference on ALL test images

import glob
from IPython.display import Image, display

for imageName in glob.glob('/content/yolov5/runs/detect/exp2/*.jpg'): #assuming JPG
    display(Image(filename=imageName))
    print("\n")

"""# HASIL TRAIN EXPERIMEN 1"""

# we can also output some older school graphs if the tensor board isn't working for whatever reason...
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/exp3/F1_curve.png', width=1000)  # view F1_curve.png

# we can also output some older school graphs if the tensor board isn't working for whatever reason...
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/exp3/PR_curve.png', width=1000)  # view PR_curve.png

# we can also output some older school graphs if the tensor board isn't working for whatever reason...
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/exp3/P_curve.png', width=1000)  # view P_curve.png

# we can also output some older school graphs if the tensor board isn't working for whatever reason...
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/exp3/R_curve.png', width=1000)  # view R_curve.png

# we can also output some older school graphs if the tensor board isn't working for whatever reason...
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/exp3/confusion_matrix.png', width=1000)  # view confusion_matrix.png

# we can also output some older school graphs if the tensor board isn't working for whatever reason...
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/exp3/results.png', width=1000)  # view results.png

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/exp3/val_batch0_labels.jpg', width=1000)

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/exp3/val_batch1_labels.jpg', width=1000)

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/exp3/val_batch2_labels.jpg', width=1000)

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/exp3/val_batch0_pred.jpg', width=1000)

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/exp3/val_batch1_pred.jpg', width=1000)

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/exp3/val_batch2_pred.jpg', width=1000)

"""# HASIL TRAIN EXPERIMEN 2"""

# we can also output some older school graphs if the tensor board isn't working for whatever reason...
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/exp3/F1_curve.png', width=1000)  # view F1_curve.png

# we can also output some older school graphs if the tensor board isn't working for whatever reason...
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/exp3/PR_curve.png', width=1000)  # view PR_curve.png

# we can also output some older school graphs if the tensor board isn't working for whatever reason...
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/exp3/P_curve.png', width=1000)  # view P_curve.png

# we can also output some older school graphs if the tensor board isn't working for whatever reason...
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/exp3/R_curve.png', width=1000)  # view R_curve.png

# we can also output some older school graphs if the tensor board isn't working for whatever reason...
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/exp3/confusion_matrix.png', width=1000)  # view confusion_matrix.png

# we can also output some older school graphs if the tensor board isn't working for whatever reason...
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/exp3/results.png', width=1000)  # view results.png

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/exp3/val_batch0_labels.jpg', width=1000)

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/exp3/val_batch1_labels.jpg', width=1000)

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/exp3/val_batch2_labels.jpg', width=1000)

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/exp3/val_batch0_pred.jpg', width=1000)

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/exp3/val_batch1_pred.jpg', width=1000)

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/exp3/val_batch2_pred.jpg', width=1000)

"""# Conclusion and Next Steps

Congratulations! You've trained a custom YOLOv5 model to recognize your custom objects.

To improve you model's performance, we recommend first interating on your datasets coverage and quality. See this guide for [model performance improvement](https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results).

To deploy your model to an application, see this guide on [exporting your model to deployment destinations](https://github.com/ultralytics/yolov5/issues/251).

Once your model is in production, you will want to continually iterate and improve on your dataset and model via [active learning](https://blog.roboflow.com/what-is-active-learning/).
"""

#export your model's weights for future use
from google.colab import files
files.download('./runs/train/exp/weights/best.pt')

project.version(dataset.version).deploy(model_type="yolov5", model_path=f"/content/yolov5/runs/train/exp3/")

#While your deployment is processing, checkout the deployment docs to take your model to most destinations https://docs.roboflow.com/inference

#Run inference on your model on a persistant, auto-scaling, cloud API

#load model
model = project.version(dataset.version).model

#choose random test set image
import os, random
test_set_loc = dataset.location + "/test/images/"
random_test_image = random.choice(os.listdir(test_set_loc))
print("running inference on " + random_test_image)

pred = model.predict(test_set_loc + random_test_image, confidence=40, overlap=30).json()
pred